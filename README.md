# RewardHackDetect

This repository contains resources for a project on detecting reward hacking in large language models (LLMs). Reward hacking occurs when AI models exploit flaws in reward functions to achieve high scores without correctly performing the intended task. This project will explore detection methods and mitigation strategies.

## Contents

- `import_models.py` — Example script demonstrating how to import and initialize open‑source language models such as Gemma and GPT‑OSS using the Hugging Face `transformers` library.
- `requirements.txt` — Python dependencies needed to run the examples.

## Usage

1. Install dependencies: `pip install -r requirements.txt`
2. Run `python import_models.py` to download and load the models.

## Notes

Gemma and GPT‑OSS are open‑weight models. Example code uses the `transformers` library; refer to their respective model cards for more details.
